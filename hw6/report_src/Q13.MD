
Model | hyper-parameters | cross-validation avg. error | public leaderboard accuracy
\\\
Classification Tree | max_depth = 9 | .474 | .57866 \\\
Classification Tree | max_depth = 7 | .4743 | x\\\
\\\
Logistic Regression | lambda = 10 | .388 | .62133\\\
Logistic Regression | lambda = 100 | .352 | x\\\
\\\
KNN Classification | K = 7 | 0.438 | .55733\\\
KNN Classification | K = 9 | 0.434 | x\\\
KNN Classification | K = 11 | 0.434 | x\\\




* THE FIRST MODEL WAS USED FOR INITIAL SUBMISSION, EXPERIMENTING WITH THE REST AS WELL AS I ACTUALLY THINK BEST PERFORMANCES WOULD BE: Tree with max depth of 9, logistic regression with lambda = 100, KNN with K = 9 or 11.

Private Scoring Predictions:


1) Tree Classification model: I believe the error range would be similar to the error present in the public set and slightly lower than cross validations errors, as depth of 9 should be balanced to avoid overfitting while trying to minimize error on unseen data. The public set seems to be performing better than cross validation predicted, indicating slightly better performance overall which I'd expect to continue in private set.

2) Logistic Regression model: The cross validation classification error is very similar to that of public test set, indicating a decent prediction job by cross validation. I'd expect a similar error range in the private test set, with room for slight variations.

3) KNN Classification model: I believe the error would slightly increase on the private set as the performance in public set seems to perform worse than cross validation predicted, indicating that the model seems to struggle more than expected and I would expect the trend to continue in private set.